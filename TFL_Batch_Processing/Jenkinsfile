pipeline {
    agent any

    environment {
        PYSPARK_PYTHON        = "/usr/bin/python3"
        PYSPARK_DRIVER_PYTHON = "/usr/bin/python3"
        SPARK_SUBMIT          = "spark-submit"    // change to spark2-submit if needed
    }

    stages {

        stage('Upgrade pip') {
            steps {
                sh '''
                    python3 -m pip install --upgrade pip setuptools wheel || true
                '''
            }
        }

        /***************************************************************
         * 1. DATA EXTRACTION FROM API (COMMENTED FOR NOW)
         * Uncomment later when you want raw extraction to run again.
         ***************************************************************
        stage('1. Data Extraction from API') {
            steps {
                echo "Running API data extraction (3 cycles)..."
                sh 'python3 TFL_Batch_Processing/src/bronze/rawdataextraction.py'
            }
        }
        ****************************************************************/
        stage('2. Data Integration (Postgres Load)') {
            steps {
                echo "Running Data Integration â€” Loading API data into Postgres..."
                sh '''
                    cd TFL_Batch_Processing/src/bronze
                    python3 dataintegration.py full
                '''
            }
        }

        stage('Run Silver Transformations') {
            steps {
                echo "Running Silver layer Spark transformations..."
                sh '''
                    cd TFL_Batch_Processing
                    spark-submit --master yarn --deploy-mode client src/silver/Transformations.py
                '''
            }
        }

        stage('3. Create Gold Tables (Hive)') {
            steps {
                echo "Running Gold Layer Hive Script..."
                sh 'cd TFL_Batch_Processing/src/gold && hive -f tfl_gold_layer.hql'
            }
        }

    }
}

